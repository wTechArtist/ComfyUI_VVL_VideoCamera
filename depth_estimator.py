import torch
import numpy as np
import json
import os
import tempfile
import cv2
import shutil
from PIL import Image
from typing import List, Dict, Any, Tuple
import pathlib

# æ·»åŠ ComfyUIç±»å‹å¯¼å…¥
try:
    from comfy.comfy_types import IO
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œåˆ›å»ºä¸€ä¸ªå…¼å®¹çš„ç±»
    class IO:
        IMAGE = "IMAGE"

class ColmapMVSDepthEstimator:
    """ä½¿ç”¨COLMAP-MVSè¿›è¡Œå¯†é›†æ·±åº¦å›¾ä¼°è®¡çš„æ ¸å¿ƒç±»"""

    def __init__(self):
        self.check_dependencies()

    def check_dependencies(self):
        """æ£€æŸ¥PyColmapä¾èµ–"""
        try:
            import pycolmap
            self.pycolmap = pycolmap
            print("PyColmap MVS å·²æˆåŠŸå¯¼å…¥")
        except ImportError as e:
            print(f"PyColmap å¯¼å…¥å¤±è´¥: {e}")
            print("è¯·å®‰è£… PyColmap: pip install pycolmap")
            raise ImportError("PyColmap æ˜¯MVSæ·±åº¦ä¼°è®¡çš„å¿…éœ€ä¾èµ–")

    def estimate_depth_from_reconstruction(self, 
                                         images: List[torch.Tensor],
                                         reconstruction_result: Dict,
                                         mvs_quality: str = "medium",
                                         output_format: str = "npy",
                                         max_image_size: int = 1200,
                                         patch_match_params: Dict = None) -> Dict:
        """ä»é‡å»ºç»“æœç”Ÿæˆå¯†é›†æ·±åº¦å›¾"""
        
        if not reconstruction_result.get("success", False):
            return {
                "success": False,
                "error": "è¾“å…¥çš„é‡å»ºç»“æœæ— æ•ˆ",
                "depth_maps": [],
                "depth_info": {}
            }

        # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
        temp_dir = tempfile.mkdtemp(prefix="colmap_mvs_")
        images_dir = os.path.join(temp_dir, "images")
        database_path = os.path.join(temp_dir, "database.db")
        sparse_path = os.path.join(temp_dir, "sparse")
        dense_path = os.path.join(temp_dir, "dense")
        
        try:
            os.makedirs(images_dir, exist_ok=True)
            os.makedirs(sparse_path, exist_ok=True)
            os.makedirs(dense_path, exist_ok=True)

            # 1. é‡æ–°ä¿å­˜å›¾ç‰‡å’Œé‡å»ºç»“æœ
            print(f"å‡†å¤‡ {len(images)} å¼ å›¾ç‰‡ç”¨äºMVS...")
            image_paths = self._save_images_to_temp(images, images_dir)
            
            # 2. é‡æ–°æ‰§è¡ŒCOLMAPé‡å»ºï¼ˆéœ€è¦å®Œæ•´çš„é‡å»ºæµç¨‹ï¼‰
            print("é‡æ–°æ‰§è¡ŒCOLMAPé‡å»º...")
            reconstructions = self._run_colmap_reconstruction(
                database_path, images_dir, sparse_path, mvs_quality
            )
            
            if not reconstructions:
                return {
                    "success": False,
                    "error": "COLMAPé‡å»ºå¤±è´¥ï¼Œæ— æ³•è¿›è¡ŒMVS",
                    "depth_maps": [],
                    "depth_info": {}
                }
            
            # 3. æ‰§è¡ŒMVSå¯†é›†é‡å»º
            print("å¼€å§‹MVSå¯†é›†é‡å»º...")
            self._run_dense_reconstruction(
                images_dir, sparse_path, dense_path, mvs_quality, 
                max_image_size, patch_match_params
            )
            
            # 4. è¯»å–å¹¶å¤„ç†æ·±åº¦å›¾
            print("å¤„ç†æ·±åº¦å›¾...")
            depth_results = self._process_depth_maps(
                dense_path, images_dir, output_format
            )
            
            return depth_results
            
        except Exception as e:
            print(f"COLMAP MVS æ·±åº¦ä¼°è®¡å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "success": False,
                "error": f"MVSæ·±åº¦ä¼°è®¡å¤±è´¥: {str(e)}",
                "depth_maps": [],
                "depth_info": {}
            }
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                shutil.rmtree(temp_dir)
            except:
                pass

    def _save_images_to_temp(self, images: List[torch.Tensor], images_dir: str) -> List[str]:
        """å°†å›¾ç‰‡å¼ é‡ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•"""
        image_paths = []
        
        for i, image_tensor in enumerate(images):
            # è½¬æ¢å¼ é‡æ ¼å¼
            if image_tensor.dim() == 4:  # Batch dimension
                image_tensor = image_tensor.squeeze(0)
            
            # ç¡®ä¿æ˜¯ HWC æ ¼å¼
            if image_tensor.dim() == 3 and image_tensor.shape[0] == 3:  # CHW -> HWC
                image_tensor = image_tensor.permute(1, 2, 0)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            image_np = image_tensor.cpu().numpy()
            
            # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
            if image_np.max() <= 1.0:
                image_np = (image_np * 255).astype(np.uint8)
            else:
                image_np = image_np.astype(np.uint8)
            
            # ä¿å­˜å›¾ç‰‡
            image_filename = f"image_{i:06d}.jpg"
            image_path = os.path.join(images_dir, image_filename)
            
            # è½¬æ¢ä¸ºBGRæ ¼å¼ä¿å­˜ï¼ˆOpenCVæ ¼å¼ï¼‰
            image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
            cv2.imwrite(image_path, image_bgr, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            image_paths.append(image_path)
        
        return image_paths

    def _run_colmap_reconstruction(self, database_path: str, images_dir: str, 
                                 sparse_path: str, quality: str):
        """è¿è¡Œå®Œæ•´çš„COLMAPé‡å»ºæµç¨‹"""
        try:
            # è®¾ç½®è´¨é‡å‚æ•°
            quality_settings = self._get_quality_settings(quality)
            
            # ç‰¹å¾æå–
            sift_options = self.pycolmap.SiftExtractionOptions()
            sift_options.max_image_size = quality_settings["max_image_size"]
            sift_options.max_num_features = quality_settings["max_num_features"]
            
            self.pycolmap.extract_features(
                database_path=database_path,
                image_path=images_dir,
                sift_options=sift_options
            )
            
            # ç‰¹å¾åŒ¹é…
            matching_options = self.pycolmap.SequentialMatchingOptions()
            matching_options.overlap = 10
            self.pycolmap.match_sequential(
                database_path=database_path,
                matching_options=matching_options
            )
            
            # å¢é‡é‡å»º
            try:
                pipeline_options = self.pycolmap.IncrementalPipelineOptions()
                if hasattr(pipeline_options, "mapper_options"):
                    mapper_opts = pipeline_options.mapper_options
                    mapper_opts.ba_refine_focal_length = True
                    mapper_opts.ba_refine_principal_point = True
            except AttributeError:
                pipeline_options = None

            if pipeline_options is not None:
                reconstructions = self.pycolmap.incremental_mapping(
                    database_path=database_path,
                    image_path=images_dir,
                    output_path=sparse_path,
                    options=pipeline_options
                )
            else:
                reconstructions = self.pycolmap.incremental_mapping(
                    database_path=database_path,
                    image_path=images_dir,
                    output_path=sparse_path
                )
            
            return reconstructions
            
        except Exception as e:
            print(f"COLMAPé‡å»ºå¤±è´¥: {e}")
            return None

    def _get_quality_settings(self, quality: str) -> Dict:
        """è·å–è´¨é‡è®¾ç½®"""
        quality_settings = {
            "low": {"max_image_size": 800, "max_num_features": 4096},
            "medium": {"max_image_size": 1200, "max_num_features": 8192},
            "high": {"max_image_size": 1600, "max_num_features": 16384},
            "extreme": {"max_image_size": 2400, "max_num_features": 32768}
        }
        return quality_settings.get(quality, quality_settings["medium"])

    def _run_dense_reconstruction(self, images_dir: str, sparse_path: str, 
                                dense_path: str, quality: str, max_image_size: int,
                                patch_match_params: Dict = None):
        """æ‰§è¡ŒMVSå¯†é›†é‡å»º"""
        
        try:
            # æ­¥éª¤1: Image undistortion
            print("1. å›¾åƒå»ç•¸å˜...")
            self.pycolmap.undistort_images(
                image_path=images_dir,
                input_path=sparse_path,
                output_path=dense_path,
                output_type="COLMAP"
            )
            
            # æ­¥éª¤2: Patch match stereo
            print("2. ç«‹ä½“åŒ¹é…...")
            self.pycolmap.patch_match_stereo(
                workspace_path=dense_path,
                workspace_format="COLMAP",
                pmvs_option_name="option-all",
                config_file_name=""
            )
            
            # æ­¥éª¤3: Stereo fusion (å¯é€‰)
            print("3. ç«‹ä½“èåˆ...")
            try:
                self.pycolmap.stereo_fusion(
                    workspace_path=dense_path,
                    workspace_format="COLMAP",
                    input_type="geometric",
                    output_path=os.path.join(dense_path, "fused.ply")
                )
            except Exception as e:
                print(f"ç«‹ä½“èåˆå¤±è´¥ï¼Œè·³è¿‡: {e}")
            
        except Exception as e:
            print(f"MVSå¯†é›†é‡å»ºè¿‡ç¨‹å‡ºé”™: {e}")
            # å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            try:
                print("å°è¯•ä½¿ç”¨å¤‡ç”¨MVSæ–¹æ³•...")
                # åªæ‰§è¡Œpatch match
                self.pycolmap.patch_match_stereo(
                    workspace_path=dense_path,
                    workspace_format="COLMAP"
                )
                
            except Exception as e2:
                print(f"å¤‡ç”¨MVSæ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                raise e

    def _process_depth_maps(self, dense_path: str, images_dir: str, 
                          output_format: str) -> Dict:
        """å¤„ç†ç”Ÿæˆçš„æ·±åº¦å›¾"""
        
        depth_maps = []
        depth_info = {
            "num_depth_maps": 0,
            "depth_range": {"min": float('inf'), "max": float('-inf')},
            "resolution": None,
            "format": output_format
        }
        
        try:
            # æŸ¥æ‰¾æ·±åº¦å›¾æ–‡ä»¶
            stereo_dir = os.path.join(dense_path, "stereo", "depth_maps")
            if not os.path.exists(stereo_dir):
                # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
                possible_paths = [
                    os.path.join(dense_path, "depth_maps"),
                    os.path.join(dense_path, "stereo"),
                    dense_path
                ]
                
                for path in possible_paths:
                    if os.path.exists(path):
                        depth_files = [f for f in os.listdir(path) if f.endswith('.geometric.bin')]
                        if depth_files:
                            stereo_dir = path
                            break
            
            if not os.path.exists(stereo_dir):
                return {
                    "success": False,
                    "error": "æœªæ‰¾åˆ°æ·±åº¦å›¾æ–‡ä»¶",
                    "depth_maps": [],
                    "depth_info": depth_info
                }
            
            # è¯»å–æ·±åº¦å›¾æ–‡ä»¶
            depth_files = [f for f in os.listdir(stereo_dir) if f.endswith('.geometric.bin')]
            depth_files.sort()
            
            print(f"æ‰¾åˆ° {len(depth_files)} ä¸ªæ·±åº¦å›¾æ–‡ä»¶")
            
            for depth_file in depth_files:
                depth_path = os.path.join(stereo_dir, depth_file)
                
                try:
                    # è¯»å–COLMAPæ·±åº¦å›¾
                    depth_map = self._read_colmap_depth_map(depth_path)
                    
                    if depth_map is not None:
                        # æ›´æ–°æ·±åº¦èŒƒå›´ä¿¡æ¯
                        valid_depths = depth_map[depth_map > 0]
                        if len(valid_depths) > 0:
                            depth_info["depth_range"]["min"] = min(
                                depth_info["depth_range"]["min"], 
                                float(np.min(valid_depths))
                            )
                            depth_info["depth_range"]["max"] = max(
                                depth_info["depth_range"]["max"], 
                                float(np.max(valid_depths))
                            )
                        
                        if depth_info["resolution"] is None:
                            depth_info["resolution"] = depth_map.shape
                        
                        # ä¿å­˜æ·±åº¦å›¾
                        if output_format == "npy":
                            depth_data = depth_map.astype(np.float32)
                        elif output_format == "bin":
                            depth_data = depth_map.tobytes()
                        else:
                            depth_data = depth_map.astype(np.float32)
                        
                        depth_maps.append({
                            "data": depth_data,
                            "filename": depth_file.replace('.geometric.bin', f'.{output_format}'),
                            "shape": depth_map.shape,
                            "dtype": str(depth_map.dtype)
                        })
                        
                except Exception as e:
                    print(f"å¤„ç†æ·±åº¦å›¾ {depth_file} å¤±è´¥: {e}")
                    continue
            
            depth_info["num_depth_maps"] = len(depth_maps)
            
            return {
                "success": True,
                "depth_maps": depth_maps,
                "depth_info": depth_info
            }
            
        except Exception as e:
            print(f"å¤„ç†æ·±åº¦å›¾å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"å¤„ç†æ·±åº¦å›¾å¤±è´¥: {str(e)}",
                "depth_maps": [],
                "depth_info": depth_info
            }

    def _read_colmap_depth_map(self, depth_path: str) -> np.ndarray:
        """è¯»å–COLMAPæ ¼å¼çš„æ·±åº¦å›¾"""
        try:
            # COLMAPæ·±åº¦å›¾æ˜¯äºŒè¿›åˆ¶æ ¼å¼
            with open(depth_path, 'rb') as f:
                # è¯»å–å¤´éƒ¨ä¿¡æ¯
                width = int.from_bytes(f.read(4), 'little')
                height = int.from_bytes(f.read(4), 'little')
                channels = int.from_bytes(f.read(4), 'little')
                
                # è¯»å–æ·±åº¦æ•°æ®
                depth_data = np.frombuffer(f.read(), dtype=np.float32)
                depth_map = depth_data.reshape((height, width, channels))
                
                # å¦‚æœæ˜¯å¤šé€šé“ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“
                if channels > 1:
                    depth_map = depth_map[:, :, 0]
                
                return depth_map
                
        except Exception as e:
            print(f"è¯»å–æ·±åº¦å›¾å¤±è´¥: {e}")
            # å°è¯•ä½¿ç”¨PyColmapè¯»å–
            try:
                depth_map = self.pycolmap.read_array(depth_path)
                return depth_map
            except:
                return None


class ImageSequenceDepthEstimator:
    """å›¾ç‰‡åºåˆ—æ·±åº¦ä¼°è®¡èŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE", {
                    "tooltip": "è¾“å…¥å›¾ç‰‡åºåˆ—"
                }),
            },
            "optional": {
                "mvs_quality": (["low", "medium", "high", "extreme"], {
                    "default": "medium",
                    "tooltip": "MVSé‡å»ºè´¨é‡ï¼Œhigherè´¨é‡éœ€è¦æ›´å¤šæ—¶é—´å’Œå†…å­˜"
                }),
                "output_format": (["npy", "bin"], {
                    "default": "npy",
                    "tooltip": "æ·±åº¦å›¾è¾“å‡ºæ ¼å¼"
                }),
                "max_image_size": ("INT", {
                    "default": 1200,
                    "min": 400,
                    "max": 4000,
                    "step": 100,
                    "tooltip": "MVSå¤„ç†çš„æœ€å¤§å›¾åƒå°ºå¯¸"
                }),
                "save_to_disk": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦å°†æ·±åº¦å›¾ä¿å­˜åˆ°ç£ç›˜"
                }),
                "output_directory": ("STRING", {
                    "default": "./depth_output",
                    "tooltip": "æ·±åº¦å›¾ä¿å­˜ç›®å½•"
                })
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("depth_maps_info", "depth_statistics", "saved_files_info")
    FUNCTION = "estimate_depth_maps"
    CATEGORY = "ğŸ’ƒVVL/VideoCamera"

    def __init__(self):
        try:
            self.estimator = ColmapMVSDepthEstimator()
        except ImportError as e:
            print(f"COLMAP MVSåˆå§‹åŒ–å¤±è´¥: {e}")
            self.estimator = None

    def estimate_depth_maps(self, images,
                          mvs_quality: str = "medium",
                          output_format: str = "npy",
                          max_image_size: int = 1200,
                          save_to_disk: bool = True,
                          output_directory: str = "./depth_output") -> tuple:
        """ä»å›¾ç‰‡åºåˆ—ä¼°è®¡æ·±åº¦å›¾çš„ä¸»å‡½æ•°"""
        
        try:
            if self.estimator is None:
                raise RuntimeError("COLMAP MVSåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥PyColmapå®‰è£…")
            
            # æ£€æŸ¥è¾“å…¥
            if images is None:
                raise ValueError("æœªæä¾›å›¾ç‰‡è¾“å…¥")
            
            # è½¬æ¢è¾“å…¥æ ¼å¼
            if isinstance(images, torch.Tensor):
                if images.dim() == 4:  # Batch of images
                    image_list = [images[i] for i in range(images.shape[0])]
                else:  # Single image
                    image_list = [images]
            elif isinstance(images, list):
                image_list = images
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å›¾ç‰‡è¾“å…¥æ ¼å¼: {type(images)}")
            
            print(f"å¼€å§‹MVSæ·±åº¦ä¼°è®¡ï¼Œå¤„ç† {len(image_list)} å¼ å›¾ç‰‡")
            
            # æ‰§è¡Œæ·±åº¦ä¼°è®¡
            result = self.estimator.estimate_depth_from_reconstruction(
                images=image_list,
                reconstruction_result={"success": True},  # ç®€åŒ–çš„é‡å»ºç»“æœ
                mvs_quality=mvs_quality,
                output_format=output_format,
                max_image_size=max_image_size
            )
            
            if not result["success"]:
                raise RuntimeError(f"æ·±åº¦ä¼°è®¡å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            # å‡†å¤‡è¾“å‡ºä¿¡æ¯
            depth_maps_info = self._format_depth_maps_info(result["depth_maps"], output_format)
            depth_statistics = self._format_depth_statistics(result["depth_info"])
            
            # ä¿å­˜æ–‡ä»¶åˆ°ç£ç›˜
            saved_files_info = ""
            if save_to_disk and result["depth_maps"]:
                saved_files_info = self._save_depth_maps_to_disk(
                    result["depth_maps"], output_directory, output_format
                )
            else:
                saved_files_info = json.dumps({
                    "saved": False,
                    "reason": "save_to_diskä¸ºFalseæˆ–æ— æ·±åº¦å›¾æ•°æ®"
                }, ensure_ascii=False, indent=2)
            
            print(f"æˆåŠŸç”Ÿæˆ {len(result['depth_maps'])} ä¸ªæ·±åº¦å›¾")
            
            return (depth_maps_info, depth_statistics, saved_files_info)
            
        except Exception as e:
            error_msg = f"æ·±åº¦å›¾ä¼°è®¡å‡ºé”™: {str(e)}"
            print(error_msg)
            
            # è¿”å›é”™è¯¯ä¿¡æ¯
            error_json = json.dumps({"error": error_msg, "success": False}, ensure_ascii=False, indent=2)
            
            return (error_json, error_json, error_json)

    def _format_depth_maps_info(self, depth_maps: List[Dict], output_format: str) -> str:
        """æ ¼å¼åŒ–æ·±åº¦å›¾ä¿¡æ¯"""
        info = {
            "num_depth_maps": len(depth_maps),
            "output_format": output_format,
            "depth_maps": []
        }
        
        for i, depth_map in enumerate(depth_maps):
            map_info = {
                "index": i,
                "filename": depth_map["filename"],
                "shape": depth_map["shape"],
                "dtype": depth_map["dtype"],
                "data_size_bytes": len(depth_map["data"]) if isinstance(depth_map["data"], bytes) else depth_map["data"].nbytes
            }
            info["depth_maps"].append(map_info)
        
        return json.dumps(info, ensure_ascii=False, indent=2)

    def _format_depth_statistics(self, depth_info: Dict) -> str:
        """æ ¼å¼åŒ–æ·±åº¦ç»Ÿè®¡ä¿¡æ¯"""
        return json.dumps(depth_info, ensure_ascii=False, indent=2)

    def _save_depth_maps_to_disk(self, depth_maps: List[Dict], 
                                output_dir: str, output_format: str) -> str:
        """ä¿å­˜æ·±åº¦å›¾åˆ°ç£ç›˜"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            saved_files = []
            
            for depth_map in depth_maps:
                filename = depth_map["filename"]
                filepath = os.path.join(output_dir, filename)
                
                if output_format == "npy":
                    np.save(filepath, depth_map["data"])
                elif output_format == "bin":
                    with open(filepath, 'wb') as f:
                        if isinstance(depth_map["data"], bytes):
                            f.write(depth_map["data"])
                        else:
                            f.write(depth_map["data"].tobytes())
                
                saved_files.append({
                    "filename": filename,
                    "filepath": filepath,
                    "size_bytes": os.path.getsize(filepath)
                })
            
            result = {
                "saved": True,
                "output_directory": output_dir,
                "num_files": len(saved_files),
                "files": saved_files,
                "total_size_mb": sum(f["size_bytes"] for f in saved_files) / (1024 * 1024)
            }
            
            return json.dumps(result, ensure_ascii=False, indent=2)
            
        except Exception as e:
            error_result = {
                "saved": False,
                "error": str(e),
                "output_directory": output_dir
            }
            return json.dumps(error_result, ensure_ascii=False, indent=2)


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ImageSequenceDepthEstimator": ImageSequenceDepthEstimator
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageSequenceDepthEstimator": "VVL Image Sequence Depth Estimator (COLMAP-MVS)"
} 